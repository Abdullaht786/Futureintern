# -*- coding: utf-8 -*-
"""Predicting attrition in synthetic data is hard

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/predicting-attrition-in-synthetic-data-is-hard-d677eed7-9845-4261-a793-0ae60a010213.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20241015/auto/storage/goog4_request%26X-Goog-Date%3D20241015T064301Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3ef03e563f5219ea3936f3a44a2a2e722da338604a5e07ba950993883600aebbb9cd866d58fdf311e79bfb1d7cd1a1bf213271686465eec347fbc47efe66c12e866521a53ebfa07c9986dd5130ccadc1e75f55decec9fb46afd890507ef63cf6cad4455d7f3e941d5d76329af1e43fec4e8213b13f37426e53c9911eda7d1de793c75b068b76d720ea13ee4d3f5e24fb9e04797bd436874990440716c42ae4a8521f30a72b99cddc5a19c66eea191f23d7c76966c93ac8e182bc30673bf9d5d45704f0e57b615f663bd49c34e0c0116a45b81c43d21192ee6185ccc78346e326eeae79deec63437c1f3a2ae6ad1150bbeae50aad1ed55d9eb4ccbfd6a422ab22
"""

import pandas as pd

COLUMNS = ['Age', 'Years_at_Company', 'Satisfaction_Level', 'Average_Monthly_Hours', 'Promotion_Last_5Years', 'Salary',
           'Gender_Female', 'Gender_Male',
           'Department_Engineering', 'Department_Finance', 'Department_HR', 'Department_Marketing', 'Department_Sales',
           'Job_Title_Accountant', 'Job_Title_Analyst', 'Job_Title_Engineer', 'Job_Title_HR Specialist', 'Job_Title_Manager']
DATA = '/kaggle/input/employee-attrition-data-prediction/employee_attrition_data.csv'
TARGET = 'Attrition'

df = pd.read_csv(filepath_or_buffer=DATA, index_col=['Employee_ID'])
for column in ['Promotion_Last_5Years', 'Attrition']:
    df[column] = df[column].astype(bool)
df = pd.get_dummies(data=df, columns=['Gender', 'Department', 'Job_Title'])
df.head()

"""Is our target class balanced?"""

df[TARGET].value_counts(normalize=True).to_dict()

import arrow
from umap import UMAP

time_start = arrow.now()
umap = UMAP(random_state=2024, verbose=True, n_jobs=1, low_memory=False, n_epochs=500)
df[['x', 'y']] = umap.fit_transform(X=df[COLUMNS])
print('done with UMAP in {}'.format(arrow.now() - time_start))

import warnings
from plotly import express

warnings.filterwarnings(action='ignore', category=FutureWarning)
express.scatter(data_frame=df, x='x', y='y', color=TARGET, facet_col=TARGET)

"""These plots look essentially identical; this suggests that this is a tough problem."""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(df[COLUMNS], df[TARGET], test_size=0.2, random_state=2024, stratify=df[TARGET])
model = LogisticRegression(max_iter=500, tol=1e-12).fit(X_train, y_train)
print('model fit in {} iterations'.format(model.n_iter_[0]))

print('accuracy: {:5.4f}'.format(accuracy_score(y_true=y_test, y_pred=model.predict(X=X_test))))

"""Our regression model does a better job of finding people who stay with the company, but it is not much better than always guessing True or False."""

from plotly import express

express.histogram(x=COLUMNS, y=model.coef_[0])

"""These regression coefficients look reasonable, but unfortunately there isn't much signal in our data."""

from sklearn.metrics import classification_report

print(classification_report(zero_division=0 , y_true=y_test, y_pred=model.predict(X=X_test)))